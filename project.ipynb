{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LING 334 Final Project: Machine Translation using LSTM"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import time\n",
    "from torch import nn, utils, Tensor\n",
    "import numpy as np\n",
    "from linecache import getline\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import spacy\n",
    "\n",
    "# spacy.prefer_gpu()\n",
    "device = torch.device(\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset considerations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File path definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "EN_PATH = 'data/fr-en/europarl-v7.fr-en.en'\n",
    "FR_PATH = 'data/fr-en/europarl-v7.fr-en.fr'\n",
    "FR_EN_PAIRS_PATH = 'data/fr-en_pairs.pickle'\n",
    "\n",
    "EN_TRAIN_PATH = 'data/train.en'\n",
    "EN_TEST_PATH = 'data/test.en'\n",
    "FR_TRAIN_PATH = 'data/train.fr'\n",
    "FR_TEST_PATH = 'data/test.fr'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining data into one file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_pairs = []\n",
    "with open(EN_PATH) as en:\n",
    "    en = en.readlines()\n",
    "    with open(FR_PATH) as fr:\n",
    "        fr = fr.readlines()\n",
    "        for i in range(len(en)):\n",
    "            sentence_pairs.append({'en': en[i].strip(),\n",
    "                                   'fr': fr[i].strip()})\n",
    "with open(FR_EN_PAIRS_PATH, 'wb') as pairs_file:\n",
    "    pickle.dump(sentence_pairs, pairs_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(FR_EN_PAIRS_PATH, 'rb') as fr_en_file:\n",
    "    pairs = pickle.load(fr_en_file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing spaCy languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_nlp = spacy.load(\"en_core_web_lg\", enable=[])\n",
    "fr_nlp = spacy.load(\"fr_core_news_lg\", enable=[])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and testing data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(EN_PATH) as en:\n",
    "    with open(FR_PATH) as fr:\n",
    "        en_train, en_test, fr_train, fr_test = train_test_split(en.readlines(), fr.readlines(), train_size=0.8, test_size=0.2)\n",
    "        with open(EN_TRAIN_PATH, 'w') as f:\n",
    "            f.writelines(en_train)\n",
    "        with open(EN_TEST_PATH, 'w') as f:\n",
    "            f.writelines(en_test)\n",
    "        with open(FR_TRAIN_PATH, 'w') as f:\n",
    "            f.writelines(fr_train)\n",
    "        with open(FR_TEST_PATH, 'w') as f:\n",
    "            f.writelines(fr_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset class definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentencePairDataset(utils.data.Dataset):\n",
    "    def __init__(self, source_path, target_path):\n",
    "        self.source_path = source_path\n",
    "        self.target_path = target_path\n",
    "\n",
    "    def __len__(self):\n",
    "        with open(self.source_path) as f:\n",
    "            return len(f.readlines())\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        return (getline(self.source_path, idx), getline(self.target_path, idx))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM node definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.W = nn.Parameter(Tensor(input_size, hidden_size * 4))\n",
    "        self.U = nn.Parameter(Tensor(hidden_size, hidden_size * 4))\n",
    "        self.b = nn.Parameter(torch.zeros(hidden_size * 4))\n",
    "        self.initialize_parameters()\n",
    "\n",
    "    def initialize_parameters(self):\n",
    "        std_dev = 1.0 / math.sqrt(self.hidden_size)\n",
    "        nn.init.uniform_(self.W, -std_dev, std_dev)\n",
    "        nn.init.uniform_(self.U, -std_dev, std_dev)\n",
    "    \n",
    "    def forward(self, input, hidden):\n",
    "        h_t, c_t = hidden\n",
    "\n",
    "        gates = (input @ self.W) + (h_t @ self.U) + self.b\n",
    "\n",
    "        in_g, forget_g, cell_g, out_g = gates.chunk(4, 1)\n",
    "        in_g = torch.sigmoid(in_g)\n",
    "        forget_g = torch.sigmoid(forget_g)\n",
    "        cell_g = torch.tanh(cell_g)\n",
    "        out_g = torch.sigmoid(out_g)\n",
    "\n",
    "        c_t_1 = (forget_g * c_t) + (in_g * cell_g)\n",
    "        return out_g * torch.tanh(c_t_1), c_t_1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, node, input_size, hidden_size, depth, dropout):\n",
    "        super().__init__()\n",
    "        self.node = node\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.depth = depth\n",
    "        # if depth == 1:\n",
    "        #     self.layers = [node(input_size, hidden_size)]\n",
    "        # elif depth > 1:\n",
    "        #     self.layers = [node(input_size, hidden_size)].extend([node(hidden_size, hidden_size) for _ in range(depth - 1)])\n",
    "        self.layers = [node(input_size, hidden_size).to(device)]\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, input_sequence):\n",
    "        batch_size, sequence_len, input_size = input_sequence.size()\n",
    "        assert input_size == self.input_size\n",
    "\n",
    "        input_sequence = self.dropout(input_sequence)\n",
    "\n",
    "        hidden = (torch.zeros(batch_size, self.hidden_size).to(device), torch.zeros(batch_size, self.hidden_size).to(device))\n",
    "\n",
    "        for layer in self.layers:\n",
    "            for t in range(sequence_len):\n",
    "                input = input_sequence[:, t, :]\n",
    "                hidden = layer(input, hidden)\n",
    "        \n",
    "        return hidden\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, node, output_size, hidden_size, depth, dropout):\n",
    "        super().__init__()\n",
    "        self.node = node\n",
    "        self.output_size = output_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.depth = depth\n",
    "        # if depth == 1:\n",
    "        #     self.layers = [LSTM(output_size, hidden_size)]\n",
    "        # elif depth > 1:\n",
    "        #     self.layers = [LSTM(output_size, hidden_size)].extend([LSTM(hidden_size, hidden_size) for _ in range(depth - 1)])\n",
    "        self.layer = node(output_size, hidden_size).to(device)\n",
    "        self.out_layer = nn.Linear(hidden_size, output_size).to(device)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, input_token, hidden):\n",
    "        batch_size, input_size = input_token.size()\n",
    "        assert input_size == self.output_size\n",
    "\n",
    "        input_token = self.dropout(input_token)\n",
    "\n",
    "        h_t_1, c_t_1 = self.layer(input_token, hidden)\n",
    "\n",
    "        output = self.out_layer(h_t_1)\n",
    "\n",
    "        return output, (h_t_1, c_t_1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Translator module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Translator(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device, source, target, max_length):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "        self.source = source\n",
    "        self.target = target\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def forward(self, input_sentence):\n",
    "        batch_size = len(input_sentence)\n",
    "        documents = list(self.source.pipe(input_sentence))\n",
    "        \n",
    "        input_tokens = torch.zeros(batch_size, self.max_length, self.encoder.input_size).to(device)\n",
    "        for i, doc in enumerate(documents):\n",
    "            if len(doc) >= self.max_length:\n",
    "                for token_i in range(self.max_length):\n",
    "                    input_tokens[i, token_i] = Tensor(doc[token_i].vector)\n",
    "            else:\n",
    "                for token_i in range(self.max_length):\n",
    "                    if token_i in range(len(doc)):\n",
    "                        input_tokens[i, token_i] = Tensor(doc[token_i].vector)\n",
    "                    else:\n",
    "                        input_tokens[i, token_i] = torch.zeros(self.encoder.input_size)\n",
    "\n",
    "        hidden = self.encoder(input_tokens)\n",
    "\n",
    "        decoder_input = torch.zeros(batch_size, self.decoder.output_size).to(device)\n",
    "\n",
    "        output_tokens = torch.zeros(batch_size, self.max_length, self.decoder.output_size).to(device)\n",
    "\n",
    "        for t in range(1, self.max_length):\n",
    "            output, hidden = self.decoder(decoder_input, hidden)\n",
    "\n",
    "            output_tokens[:, t, :] = output\n",
    "\n",
    "            decoder_input = output\n",
    "\n",
    "        outputs = []\n",
    "        for sentence in output_tokens:\n",
    "            words = []\n",
    "            for token in sentence:\n",
    "                query = token.unsqueeze(0).detach().cpu()\n",
    "                words.append(self.target.vocab[self.target.vocab.vectors.most_similar(query)[0][0]].text)\n",
    "            outputs.append(' '.join(words))\n",
    "        return outputs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_SIZE = 64\n",
    "N_LAYERS = 2\n",
    "MAX_LENGTH = 50\n",
    "ENC_DROPOUT = 0.5\n",
    "DEC_DROPOUT = 0.5\n",
    "N_EPOCHS = 10\n",
    "LR = 0.001\n",
    "GRAD_CLIP = 1\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "encoder = Encoder(LSTM, en_nlp.vocab.vectors_length, HIDDEN_SIZE, N_LAYERS, ENC_DROPOUT).to(device)\n",
    "decoder = Decoder(LSTM, fr_nlp.vocab.vectors_length, HIDDEN_SIZE, N_LAYERS, DEC_DROPOUT).to(device)\n",
    "model = Translator(encoder, decoder, device, en_nlp, fr_nlp, MAX_LENGTH).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "criterion = torch.nn.CrossEntropyLoss(ignore_index=0)\n",
    "\n",
    "train_set = SentencePairDataset(EN_TRAIN_PATH, FR_TRAIN_PATH)\n",
    "test_set = SentencePairDataset(EN_TEST_PATH, FR_TEST_PATH)\n",
    "train_loader = utils.data.DataLoader(train_set, batch_size=BATCH_SIZE)\n",
    "test_loader = utils.data.DataLoader(test_set, batch_size=BATCH_SIZE)\n",
    "\n",
    "training_loss = []\n",
    "testing_loss = []\n",
    "\n",
    "def train(model, loader, optimizer, criterion, grad_clip):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for i, batch in enumerate(loader):\n",
    "        (source, target) = batch\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(source)\n",
    "\n",
    "        if i == 0:\n",
    "            print(target)\n",
    "            print(output)\n",
    "\n",
    "        output_for_loss = [[token.orth for token in doc] for doc in model.target.pipe(output)]\n",
    "        target_for_loss = [[token.orth for token in doc] for doc in model.target.pipe(target)]\n",
    "        loss = criterion(output_for_loss, target_for_loss)\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    return epoch_loss / len(loader)\n",
    "\n",
    "def evaluate(model, loader, criterion):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(loader):\n",
    "            (source, target) = batch\n",
    "            \n",
    "            output = model(source)\n",
    "\n",
    "            output_for_loss = [[token.orth for token in doc] for doc in model.target.pipe(output)]\n",
    "            target_for_loss = [[token.orth for token in doc] for doc in model.target.pipe(target)]\n",
    "            loss = criterion(output_for_loss, target_for_loss)\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "    \n",
    "    return epoch_loss / len(loader)\n",
    "\n",
    "def epoch_time(start, end):\n",
    "    elapsed = end - start\n",
    "    mins = int(elapsed / 60)\n",
    "    secs = int(elapsed - (mins * 60)) \n",
    "    return mins, secs\n",
    "\n",
    "start_time = time.time()\n",
    "for epoch in range(N_EPOCHS):\n",
    "    train_loss = train(model, train_loader, optimizer, criterion, GRAD_CLIP)\n",
    "    test_loss = evaluate(model, test_loader, criterion)\n",
    "    training_loss.append(train_loss)\n",
    "    testing_loss.append(test_loss)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    mins, secs = epoch_time(start_time, end_time)\n",
    "    print(f'Epoch: {epoch+1:02} | Time: {mins}m {secs}s') \n",
    "    print(f'\\tTrain Loss: {train_loss:.3f}')\n",
    "    print(f'\\t Test Loss: {test_loss:.3f}')\n",
    "    start_time = time.time()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
